---
layout: Post  # 必须
title: Streaming 101 - The world beyond batch  # 博客标题（必须）
subtitle: 方便回顾，自己做个翻译记录  # 博客副标题（可选）
date: 2022-08-31  # 博客日期，会显示在文章头部（可选）
useHeaderImage: true  # 是否在博客中显示封面图：`image`（显示） / `text`（不显示）（可选，默认为 `text`）
headerImage: /img/blog_cover/2021/05/cdh_install_blog_cover.png   # 博客封面图（必须，即使上一项选了 `text`，图片也需要在首页显示）
headerMask: rgba(40, 57, 101, .4)  # 封面图遮罩（可选）
catalog: true  # 是否启用右侧目录：false / true（可选，默认为 false）
permalinkPattern: /post/:year/:month/:slug/
tags:  # 博客标签
- 大数据
- streaming
---

> Editor's Note: 这是关于数据处理演变两个系列的第一部分，主要涉及 流式系统，无界数据集(unbounded data sets)，以及大数据的未来。

如今，流式数据处理(Streaming data processing)是大数据领域的一件大事，并且有充分的理由，包括：

- 企业渴望更实时的数据，使用 Streaming Processing 是实现低延迟的一个很好的方式。
- 海量、无边界的数据集在现代商业中越来越普遍，使用专门为这类无止境的数据设计的系统更容易驾驭这些海量数据。
- 在数据到达时就对其进行处理，可以随着时间的推移更均匀地分散工作负载，从而产生更一致和可预测的资源消耗。

尽管这种业务驱动的对"流"的兴趣激增，但是相较于批处理而言，现有的大多数流式系统仍然不成熟，这导致该领域最近出现了许多令人兴奋的积极发展。

作为在 Google 大规模流式系统(Millwheel, Cloud Dataflow)从事过五年多的从业者，我对当下"流"的时代潮流感到高兴。我也有兴趣确保让人们了解流式系统的所有功能以及如何最好地使用它们，特别是考虑到大多数现有批处理和流式系统之间仍然存在语义差距。由于我有很多内容要介绍，所以我将把它分开两个单独的帖子:

1. Streaming101：第一篇文章将介绍一些基本的背景信息并澄清一些术语，然后再深入了解有关时间域(time domains)的详细信息以及对批处理和流式数据处理常用方法的高级概述。
2. Dataflow 模型：第二篇文章将主要包括 Cloud Dataflow 使用的统一批处理 + 流模型，并通过一个适用于各种用例的具体示例来促进。之后，我将以对现有批处理和 流式系统 的简要语义比较作为结束。

## 1 背景知识

首先，我将介绍一些重要的背景信息，这些信息将有助于构建我想讨论的其余主题，主要分为三个特定部分：

- 术语：要准确地谈论复杂的话题，需要对术语进行准确的定义。对于那些在当前使用中已经具有过多解释的术语(i.e., 在不同语境下有不同的含义的术语)，我将尽量在提到它们的时候明确我所要表达的意思。
- 功能：我会列举现有流式系统常见的缺点，提出一个我觉得流式系统应该具备的功能，解决现在或者将来数据处理需求。
- 时间域（time domains）：我会引入与数据处理相关的两个主要时间域，分析它们的关系，并指出这两个时间域带来的困难。

### 1.1 术语：什么是流媒体(Streaming)？

在我们深入之前，我想先弄清楚一件事：什么是 streaming ？"Streaming" 这个词现在用来表示各种不同的东西（为了简单起见，到目前为止我都使用的有些随意。i.e., 作者应该想表达 "streaming" 这个词被随意的使用，并没有明确的去定义这个词吧），这可能会导致对Streaming 的真正含义或流式系统实际上是什么产生误解，因此，我更愿意稍微精确地定义这个术语。

问题的症结在于，很多东西应该被描述为他们是什么(比如，无界数据处理(unbounded data processing)和近似结果(approximate results), 等等)，但是实际上他们已经被通俗的描述为以前是如何实现的(即，通过流式计算引擎)。这种缺乏精确性的术语使 Streaming 的真正含义变得模糊，并且在某些情况下，流式系统本身的主题意味着它们的能力仅限于那些常被称为 "Streaming" 的特征(i.e., 流式系统只是有那些被称为 streaming 的特性)，例如近似或推测结果。鉴于精心设计的流式系统与任何现有的批处理引擎一样能够（在技术上更是如此）产生正确、一致、可重复的结果，我更愿意==将术语 Streaming 定性为一个非常具体的含义：一种在设计时考虑到无限数据集的数据处理引擎==。(为了完整起见，值得强调的是，这个定义包括真正的 Streaming 和微批处理(micro-batch)实现。)

至于"Streaming"的其他常见用法，以下是我经常听到的一些用法，每种用法都带有更精确、更具描述性的术语，我建议我们作为一个社区应该尝试采用: 

1. 无界数据(unbounded data)：一种持续产生并且无穷的数据集，通常被称为"流式数据"。但是，用 streaming 和 batch 这两个术语来描述数据集是存在问题的，因为它们只能表示使用某种类型的执行引擎来处理这些数据。实际上，所讨论的两种数据集的主要区别在于它们的有限性。因此，最好用能够捕捉这种区别的术语来描述它们。所以，我将无穷的 "streaming" 数据集称为 *无界数据*，将有限的 "batch" 数据集称为 *有界数据*
2. 无界数据处理(unbounded data processing)：一种持续的数据处理模式，适用于上述类型的无界数据。我自己也喜欢用 streaming 来描述这类数据处理，但在这种情况下使用 streaming 意味着使用 streaming 执行引擎，这简直就是误导；自从首次构思批处理系统以来，批处理引擎的重复运行已被用于处理无界数据（相反，设计良好的流式系统不仅仅是在有界数据上进行批量处理的能力）。因此，为了清楚起见，我将这种数据处理模式称为 *无界数据处理*。
3. 低延迟、近似和推测结果(low-latency, approximate, and/or speculative results)：这些类型的结果常和 streaming 引擎关联在一起。传统上，批处理系统在设计时并未考虑到低延迟或推测结果，这仅仅是历史遗留问题。事实上，批处理引擎是完全能够提供近似结果的。因此，与上面的术语一样，将这些结果描述为它们的本质（低延迟、近似或推测）要比描述它们在历史上的表现方式（通过 streaming 引擎）要好得多。

从现在开始，每次我使用 "streaming" 这个术语时，你都可以直接认为我的意思是为无界数据集设计的执行引擎，仅此而已。而当我提及其他术语时，我会明确地说无界数据、无界数据处理或低延迟/近似/推测结果。这些是我们在 Cloud Dataflow 中采用的术语，我鼓励其他人采取类似的立场。

### 1.2 关于 streaming 被逐渐夸大的局限性

接下来，我们讨论一下流式系统能做什么和不能做什么，重点是能做什么。我想在这些帖子中传达的最大事情之一就是设计良好的 流式系统 的能力。流式系统 长期以来一直被归入一个提供低延迟、近似/推测结果的小众市场，通常与功能更强大的批处理系统结合使用以提供最终正确的结果，即，Lambda架构。

对于那些还不熟悉 Lambda 架构的人来说，基本思想是在批处理系统旁边运行一个流式系统，两者都执行基本相同的计算。流式系统提供低延迟、不精确的结果(这是因为使用的近似算法，或者系统本身不支持精确性)，之后batch系统开始执行，提供精确的结果。起初是由 Twitter 的 Nathna Marz (Storm的创始人)提出来的，最终非常成功，因为这在当时是个绝妙的想法。当时流引擎在正确性方面有点让人失望，批处理引擎和你想象的一样笨拙，所以 Lambda 给了你一种方法来吃众所周知的蛋糕(i.e., Lambda架构提供了一种可行的解决方案，并且很受欢迎)。不幸的是，维护 Lambda 系统很麻烦：您需要构建、配置和维护管道的两个独立版本，最后还要以某种方式合并两个管道的结果。

作为一个多年来致力于强一致性流引擎的人，我也发现 Lambda 架构的整个原理有点令人讨厌。不出所料，当 Jay Kreps 的《质疑 Lambda 架构》一文发布时，我就成了他的忠实粉丝。这是反对双模式执行必要性的第一个高度可见的声明之一。Kreps 在使用像 Kafka 这样的可重放系统(replayable system)作为流互连(streaming interconnect)的情况下解决了可重复性问题，甚至提出了 Kappa 架构，这基本上意味着使用设计良好的系统可以为眼前的作业构建合适的单个管道，并运行它。我不认为这个概念本身需要一个名字，但我原则上完全支持这个想法。

老实说，我认为应该更进一步，我认为设计合理的流式系统实际上是提供了严格批处理功能的超集(i.e., 流式系统应该包含了严格的批处理功能)。~~Modulo(同余理论)可能是个efficiency delta(不是很理解作者表达的意思)~~，到那时也许不再需要现在的这种批处理系统。感谢 Flink 的伙计们将这个想法铭记在心，并构建了一个"任何时候都是流"(all-streaming-all-the-time)的系统，即使在"batch"模式下也是如此，我很喜欢它。

所有这一切的必然结果就是，流式系统的成熟，与强大的无界数据处理架构相结合，最终，Lambda架构将会成为大数据的历史。我认为这已经在实现了。实现这个(i.e., 打败批处理)，只需要完成两件事：

1. 正确性correctness。使得streaming能和batch等同。本质上，正确性归结起来就是一致性存储的问题。streaming系统需要一种类似给状态创建持久化检查点的方法(正如Kreps在文章“为何本地状态是数据流处理的基本原语“)，使得系统即使在机器挂掉的情况下也能保持一致性。早在几年前Spark Streaming首次出现时，它就成为了streaming领域里黑暗中的灯塔(一种比喻的说法，意思是先驱、领头羊)。幸运的是，自此一切有了新的发展，但是仍然有许多streaming系统不提供强一致性。我一直不理解为什么at-most-once语义处理还存在，但事实是它确实存在。
   再次重申一点：强一致性要求必须是exactly-once的处理语义，这是正确性的前提，只有这样才能追上并最终超越batch系统。除非毫不在意结果的正确性，否则我真诚地建议你放弃任何不提供强一致的streaming系统，不要在它们上面浪费时间。batch系统如果能够提供正确的结果，则不需要提前验证。如果你很想了解在streaming系统中如何实现强一致性，我建议你读读Millwheel和Spark Streaming这两篇论文，它们均花费了不少篇幅讲述一致性的问题。由于时间/篇幅限制，这里就不展开讨论了。
2. 时间工具tools for reasoning about time。使得streaming超越batch。处理无穷、无序的数据时，时间工具是必不可少的。当前，越来越多的需求要处理这类数据，但是现有的batch系统都缺乏必要的工具来解决此类困难。接下来的章节和下一篇文章我会着重讲述它。(无序是难点，因为大部分分布式系统都不能提供严格的顺序保证，这里的时间工具是指系统提供API，让用户自己控制超时、如何按照时间分块等等。)
   首先我们会理清时间的一些基础概念，接着深入分析什么是无穷无序的时间事件-时间差，最后讲解streaming和batch系统处理有穷和无穷数据的常见方法。

1.3 事件时间 vs. 处理时间
为了确切地讲述无穷数据处理，我们需要对时间有个清楚的理解。无论哪个数据处理系统，我们通常关心两类时间：

事件时间event time，也就是事件真正发生的时刻。
处理时间processing time，也就是事件被系统获知的时刻(可以理解为事件进入系统的时间，大部分是被应用层接收到之后附加的时间戳)
不是所有的应用场景都考虑事件时间，这样的话会简单很多；但也有不少需求是关注的，比如为带时序的用户行为建立特征、大多数付费应用和很多异常检查(比如广告的attribution就是带时许的行为，用户只用在看过广告后点击）。

理想情况下，事件时间和处理时间应该一直是相同的，即事件发生时就被处理。但现实并非如此，事件时间和处理时间之差不仅不是零，而是一个与输入、执行引擎和硬件相关的函数。下面是几个经常影响时间差的因素：

共享资源的限制，比如网络拥塞、网络分区，或者不独占场景下共享CPU
软件因素，比如分布式系统逻辑、冲突等
数据特性本身，包括key的分布、吞吐变化、乱序变化(比如很多人在整个航班中离线，等结束了再关闭飞行模式）
如果绘制一个现实系统中事件时间和处理时间的差异图，我们可以得到如下图所示。


黑色虚线代表理想情况，即事件时间和处理时间完全一致；红色实线表示现实情况。在这个例子中，系统在一开始处理有点延迟，中间逐渐接近理想情况，结束时再次有点延迟。两条线的横向距离表示两个时间的差值。基本上这个差值是处理的延迟导致的。

由于事件时间和处理时间之间的关联性不是固定不变的，因此我们不能简单用处理时间来分析数据。不幸的是，这是大多数系统处理无穷数据的方式。为了处理无穷数据，这些系统通常引入窗口这个概念来操作数据。下面我将会深入讨论窗口，它本质上是用一些临时的分界线将数据划分成一个个有穷的小块来处理。

如果要考虑正确性和利用事件时间来分析数据，那么就不能使用处理时间来定义这些临时的分界线，但这又是大多数系统采用的方法。由于这两个时间之间没有一致的关联，某些事件时间会被分割到不正确的处理时间窗口，这是由于分布式系统固有的延迟、多种数据源的在线离线特征等导致的，就没有正确性而言了，下面和另一篇文章中我会利用几个例子来讨论这个问题。

不幸的是，即使用事件时间来定义分界线，也未必正确。在无穷数据中，乱序和变化的时间差会带来一些完整性问题：两个时间之间的关联不可预测，在给定事件时间X的前提下又如何能断定已经接收到这之前所有的数据？对许多现实世界的数据源来说，是做不到的。现在大部分数据处理系统都依赖某种完整性，但是这么做让它们在处理无穷数据时遇到严重的困难。

我认为与其将无穷数据分割成有穷的、最终完整的批次，还不如设计工具能够让我们live在这种不确定性中，也就是说即使时间差不能预测，也能应对。新数据会到来，也能重新获取或修改旧数据，我们创建的系统需要自然而然地去优化完整性，而不是认为它是一个可有可无的语义。(优化完整性是指系统要提供API来控制超时)

在我们深入讨论如何实现类似Cloud Dataflow数据模型之前，我们先解决一个更有用的话题：常用的数据处理模式data processing pattern。

2 数据处理模式
此刻我们已经拥有足够多的背景知识来学习有穷和无穷数据的几种核心处理模式。接下来我们将讨论streaming和batch两种类型的数据处理（我将微批次micro-batch归拢到streaming里，因为在这个层次它们没有本质区别）。

2.1 有穷数据
处理有穷数据的方法很简单，大家都熟悉的。如下图所示，左边是一个完整的非结构化数据集，中间是数据处理引擎(一般是batch系统，不过也可以是设计良好的streaming引擎)，右边是一个处理后新的结构化数据集，包含的价值更大。


虽然这种计算模式有很多变种，但是整体的模型是十分简单的。我们更感兴趣的是无穷数据的处理。接下来我们来看看无穷数据处理的常见方式，包括传统的batch执行引擎、streaming和微批次处理。

2.2 无穷数据 — 批
batch执行引擎尽管不是为了处理无穷数据而设计的，也能用来处理无穷数据，从一开始就被业界使用了。正如大家所预料的，这类方法基本是将无穷数据划分为有穷数据的集合，而有穷数据集是适合用batch系统处理的。

2.2.1 固定窗口
最常见的利用重复运行batch引擎来处理无穷数据的方法是将输入数据划分成大小固定的窗口，然后将它们作为独立的、有穷的数据源来处理。特别地，对于一些输入源比如日志，可以自然而然地将数据拆分成以时间为单位的树状结构，这个很直观，因为基本上就是按照事件时间分块的。

而事实上，大多数系统还是需要处理完整性问题：如果因为网络分区导致日志记录发生延迟该怎么办呢？如果事件是全球范围的，但是在处理前要存储到同一个地方？如果事件是来自移动端的？这意味着我们必须要用一些特别的方法来解决：比如推迟事件的处理，直到所有数据都到达了；或者重新计算整个数据集，只要新的数据到达了。


2.2.2 会话

会话是将无穷数据集拆分地更加细致，创建了更为复杂得窗口，通常定义为活动周期，终止于不活跃的间隔。当用batch执行引擎来计算会话时，会出现一个session横跨多个块，比如下图中红色部分。通过增加batch的大家可以减少分割数目，但是带来了延迟增加的代价。另一种做法是增加额外的逻辑来分割，但是增加了复杂度。


使用传统的batch系统来计算会话，无论哪种方法都不理想。接下来我们将讲述一个更加友好的方法，即使用streaming的方式。

2.3 无穷数据 — 流
和大多数batch方法处理无穷数据相反，streaming系统是专门用来处理无穷数据的。正如我前面所讲，对于许多现实世界的分布的输入源，数据的特性不仅是无穷的，还包括：

在事件时间是高度乱序的，意味着需要处理乱序问题。
变化的时间差，意味着不能直接假设我们总是能看到大多数数据，在某个不变的处理时间内，给定事件时间X。
因此出现了一些处理这类数据的方法，我将它们大致归为以下四类：

时间无关的
近似算法
处理时间窗口
事件时间窗口
接下来一一讨论以上这四类方法。

2.3.1 时间无关算法 Time-Agnostic
时间无关处理通常用于对时间不关心，只受数据驱动的场景。因此除了基础的数据传输，streaming引擎也不需要其他特别的支持。因此，本质上目前所有streaming系统都支持时间无关的处理(忽略系统与系统之间关于一致性保证的差异)。batch系统当然也适用于无穷数据的时间无关处理，通过简单地将无穷数据划分成任意的有穷数据序列集合，再单独地处理它们。接下来我们看几个具体的例子。

Filter
过滤操作是时间无关处理的一个典型例子。假设我们在处理网络日志，需要找出特定域名的记录，则需要过滤到不符合要求的。每当记录到达时，就查看它是否属于目标域名，如果不属于就丢弃。这个操作在任何时候只和当前的事件有关，而数据是否是乱序、有穷还是无穷、时间差是否变化都无关。


Inner-Joins
Inner-Join，又称作哈希连接，是另一个时间无关的经典操作。当连接两个无穷数据集时，当各自数据都到达时，只关系连接结果。当接收到其中一个数据源的数据时，可以先把它缓存起来，当另一个数据源的数据到达时，再输出连接结果。事实上，可能需要一些垃圾回收机制来处理那些没有发送出去的临时连接结果，这就和时间有关了。

如果是outer-join处理，那就涉及到数据完整性的问题。当只接收到一方的数据时，又是如何知道另一方到底还会不会来？事实是，我们不知道，所以不得不引入超时设置，而这就与时间有关了。本质上这是窗口操作的另一种形式。


2.3.2 近似算法 Approximation

近似算法，比如近似Top-K，流式K-Means等等，处理无穷输入，生成那些你或多或少期待得到的结果。近似算法的好处是开销低，专为无穷数据而设计；缺点是这类算法有限，且实现起来比较复杂，近似的本质限制了他们不适用于所有场景。

但是值得注意的是，这类算法通常是具有时间特征的，比如decay。当数据到达时就处理，因此通常是基于处理时间的。另一个很重要的特点是它们都是提供可控的错误率。如果错误率可以根据数据到达的顺序预测出来，这些错误率就可以忽略不计，即便是无穷数据，这一点也很重要。

近似算法本身是一个很吸引人的话题，但是它们本质上是另一种时间无关处理的形式，如果忽略算法的时间特征的话。


2.3.3 窗口

接下来的两种方法都是窗口操作的变种。在深入之前，我要先讲明白什么是窗口，它就是利用时间分界线将输入的数据(有穷或者无穷)分割成有限的数据块来处理。下面的图展示了三种不同的窗口模式。


固定窗口fixed window，将数据划分成固定时间长度的数据块。如果分块对整个数据集都是同样的，这是对齐窗口aligned window的一种形式。在某些场景下，需要对不同数据集进行窗口的相移，比如针对每个key，将整个窗口的负载在时间维度上划分地更加均匀，这是不对齐窗口的一种形式，因为它们随着数据的变化而变化。
滑动窗口sliding window，是固定窗口的一种泛化，由一个固定长度和固定周期定义。如果周期小于长度，则窗口与窗口之间会有重叠。如果周期大于长度，则窗口看起来就是在时间维度上的单个数据集。因为也是固定窗口，滑动窗口通常是对齐的，虽然在某些特定场景下使用性能优化可能导致不对齐。
会话session，是动态窗口的一种形式，通常是事件序列，每个序列终止于一个不活跃间隔，不活跃间隔都是使用超时时间。会话一般用来分析用户行为数据，取决于所涉及的实际数据，长度不能提前定义。会话也是不对齐窗口的典型类型，因为实际上几乎没有两个数据集是相同的。
我们关心的是上面讨论过的两个时间：处理时间和事件时间。这两类时间上的窗口都有意义，下面我们来看看它们有什么不同，先从处理时间窗口讲起，因为它是最常见的。

处理时间窗口
当用处理时间来定义窗口时，系统会将到来的数据缓存到窗口里，直到某些处理时间过时了。举个例子，在五分钟固定窗口的场景下，系统只需要缓存五分钟内的数据，然后等所有数据都到达了，发给下游处理就行。这种方法有以下几个特性：

简单，不需要担心乱序，数据到来时就缓存起来，当窗口关闭时直接发给下游。
判断窗口结束是简单直接的，系统自己知道一个窗口的输入是不是已经都接收到了，它能很好地判断窗口是否已经完整。这意味着不需要处理晚到的数据。
如果我们需要推断一些关于数据源的情况，只需要使用处理时间。监控系统就是最好的例子，比如我们想直到一个全球化的网络服务的QPS，使用处理时间来计算是最好的办法。
但是处理时间窗口也存在一个大的缺点：如果数据之间是事件时间关联的，那么这些数据必须以事件时间的顺序到来，如果我们想用处理时间来分块的话。不幸的是分布式上输入源大部分不能保证有序。

举个例子，比如一个移动端app收集用户的数据，如果移动设备断线了，那么这个离线时间段内用户的数据就不能被上传直到设备再次上线。这意味着这个事件时间差内的数据本该已经到达，那么使用处理时间来划分窗口根本不能得到什么有用的信息。

再举个例子，许多分布式输入源可能是事件时间有序的，如果整个系统没出问题的话。


事件时间窗口
当我们需要观察输入源在事件发生时的情况时，就使用事件时间来分块数据。这是窗口操作的金本位，但是，大多数数据处理系统都不能很好地支持这一点，虽然我们知道任何强一致性系统经过一些修改时能够解决的，比如Hadoop和Spark Streaming。

下图展示了一个用事件时间将无穷数据划分成一个小时长度的固定窗口。


图中白色的实线表示两个数据的插入操作。这两个数据项到达的处理时间窗口均不能和它们所属的事件时间窗口想匹配。因此，如果在某个关心事件发生时间的场景下用处理时间来划分窗口，则计算结果是不正确的。正如我们所预料的，通过事件时间来划分窗口一定能保证事件时间的正确性。

使用事件时间窗口的另一个优点是我们可以创建大小不等的窗口，比如会话，但是不存在一个会话跨越多个块的情况。


当然，这也是有代价的，由于窗口必须比窗口的实际长度存活得更久(在处理时间上），事件时间也有两个显著得缺点。

缓存buffer：更长的生命那个要求保存更多的数据。幸运的是，现在持久化存储已经是数据处理系统中最便宜的资源，相对于CPU、网络带宽和内存来说，因此缓存不是太大的问题，至少比设计强一致性存储和内存cache容易多了。很多聚合操作不需要保存完整的输入，比如和或者均值计算。
完整性：考虑到没有一个很好的办法来决定何时一个窗口的数据都到齐了，那又怎么知道何时发布处理结果呢？事实上，这就是做不到。对于各种类型的输入，系统能利用类似Millwheel中的低水位线来可靠预测数据是否完整；但是某些情况下，正确性十分重要，比如计费系统，唯一的办法是提供一个方法让系统自己能够控制什么时候发布数据，并让系统自己反复修正最终的结果。完整性是一个非常有趣的话题，最好能有一些具体的例子来介绍，我将在下一篇文章中讨论。
3 总结
这篇包含太多信息了。如果你读到这里，你应该受到表扬，我们已经完成了一半了，让我们回顾下我们讲了什么，并且知道下一篇讲什么。让人高兴的是这篇无聊些，但是下一篇一定有趣。

澄清术语，特别是streaming的定义只限于执行引擎，而将其他术语，比如unbounded      data和近似算法都放在streaming的概念下。
分析了设计正确的batch和streaming系统，总结出 streaming是batch的功能超集 ，Lambda架构最终会被streaming取代。
提出两个重要的概念，能够帮助streaming追赶并超越batch，即完整性 和时间工具。
列出了事件时间和处理时间的关系，并且指出两个时间给我们带来的困难，根据完整性的概念，提出系统应该能够拥抱在时间上的变化，提供完整精确的结果。
分析了常用数据处理方法，包括bounded和unbounded数据，主要是batch和streaming引擎，并且把unbounded数据处理分成4类：      time-agnostic, approximation, windowing by processing time, and windowing      by event time 。
下一篇文章将包括：

从更高层面分析数据处理的概念，主要从4个方面入手：what, where, when, and how 。
详细分析如何用Dataflow Model来完成各种不同的需求。他讲帮助你更彻底的理解啥是event      time和processing time，也包括一个新的概念：watermarks
比较现有数据处理系统，特别是一些最要的特性，让我们更好的选择他们，并且鼓励大家改善他们，帮助我实现我的最终目标：让streaming成为大数据处理的最好形式